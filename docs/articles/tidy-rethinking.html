<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Extracting and visualizing tidy draws from rethinking models • tidybayes.rethinking</title>
<!-- favicons --><link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
<link rel="apple-touch-icon" type="image/png" sizes="180x180" href="../apple-touch-icon.png">
<link rel="apple-touch-icon" type="image/png" sizes="120x120" href="../apple-touch-icon-120x120.png">
<link rel="apple-touch-icon" type="image/png" sizes="76x76" href="../apple-touch-icon-76x76.png">
<link rel="apple-touch-icon" type="image/png" sizes="60x60" href="../apple-touch-icon-60x60.png">
<!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script><!-- Bootstrap --><link href="https://cdnjs.cloudflare.com/ajax/libs/bootswatch/3.4.0/paper/bootstrap.min.css" rel="stylesheet" crossorigin="anonymous">
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script><!-- bootstrap-toc --><link rel="stylesheet" href="../bootstrap-toc.css">
<script src="../bootstrap-toc.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script><link href="../extra.css" rel="stylesheet">
<meta property="og:title" content="Extracting and visualizing tidy draws from rethinking models">
<meta property="og:description" content="tidybayes.rethinking">
<meta property="og:image" content="http://mjskay.github.io/tidybayes.rethinking/logo.svg">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]--><!-- Global site tag (gtag.js) - Google Analytics --><script async src="https://www.googletagmanager.com/gtag/js?id=UA-93322-5"></script><script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-93322-5');
</script>
</head>
<body data-spy="scroll" data-target="#toc">
    <div class="container template-article">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">tidybayes.rethinking</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="Released version">2.0.3.9000</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../index.html">
    <span class="fas fa fas fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/tidy-rethinking.html">Extracting and visualizing tidy draws from rethinking models</a>
    </li>
  </ul>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
  <a href="https://github.com/mjskay/tidybayes.rethinking/">
    <span class="fab fa fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      

      </header><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1 data-toc-skip>Extracting and visualizing tidy draws from rethinking models</h1>
                        <h4 class="author">Matthew Kay</h4>
            
            <h4 class="date">2020-06-01</h4>
      
      <small class="dont-index">Source: <a href="https://github.com/mjskay/tidybayes.rethinking/blob/master/vignettes/tidy-rethinking.Rmd"><code>vignettes/tidy-rethinking.Rmd</code></a></small>
      <div class="hidden name"><code>tidy-rethinking.Rmd</code></div>

    </div>

    
    
<style type="text/css">
.kable-table table {
  margin-left: 0;
}
img {
  border: none;
}
</style>
<div id="introduction" class="section level2">
<h2 class="hasAnchor">
<a href="#introduction" class="anchor"></a>Introduction</h2>
<p>This vignette describes how to use the <code>tidybayes.rethinking</code> and <code>tidybayes</code> packages to extract <a href="http://dx.doi.org/10.18637/jss.v059.i10">tidy</a> data frames of draws from posterior distributions of model variables, fits, and predictions from models fit in Richard McElreath’s <a href="https://github.com/rmcelreath/rethinking"><code>rethinking</code> package</a>, the companion to <a href="https://xcelab.net/rm/statistical-rethinking/">Statistical Rethinking</a>.</p>
<p>Because the <code>rethinking</code> package is not on CRAN, the code necessary to support that package is kept here, in the <code>tidybayes.rethinking</code> package. For a more general introduction to <code>tidybayes</code> and its use on general-purpose Bayesian modeling languages (like Stan and JAGS), see <code><a href="http://mjskay.github.io/tidybayes/articles/tidybayes.html">vignette(“tidybayes”, package = “tidybayes”)</a></code>.</p>
<p>While this vignette generally demonstrates use of tidybayes with models fit using <code><a href="https://rdrr.io/pkg/rethinking/man/ulam.html">rethinking::ulam()</a></code> (models fit using Stan), the same functions also work for other model types in the <code>rethinking</code> package, including <code><a href="https://rdrr.io/pkg/rethinking/man/quap.html">rethinking::quap()</a></code>, <code><a href="https://rdrr.io/pkg/rethinking/man/quap.html">rethinking::map()</a></code>, and <code><a href="https://rdrr.io/pkg/rethinking/man/map2stan.html">rethinking::map2stan()</a></code>. For <code>quap()</code> and <code>map()</code>, the tidybayes functions will generate draws from the approximate posterior for you. This makes it easy to move between model types without changing your workflow.</p>
</div>
<div id="setup" class="section level2">
<h2 class="hasAnchor">
<a href="#setup" class="anchor"></a>Setup</h2>
<p>The following libraries are required to run this vignette:</p>
<div class="sourceCode" id="cb1"><html><body><pre class="r">library(magrittr)
library(dplyr)
library(purrr)
library(forcats)
library(tidyr)
library(modelr)
library(tidybayes)
library(tidybayes.rethinking)
library(ggplot2)
library(cowplot)
library(rstan)
library(rethinking)
library(ggrepel)
library(RColorBrewer)
library(gganimate)

theme_set(theme_tidybayes() + panel_border())</pre></body></html></div>
<p>These options help Stan run faster:</p>
<div class="sourceCode" id="cb2"><html><body><pre class="r">rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores())</pre></body></html></div>
</div>
<div id="example-dataset" class="section level2">
<h2 class="hasAnchor">
<a href="#example-dataset" class="anchor"></a>Example dataset</h2>
<p>To demonstrate <code>tidybayes</code>, we will use a simple dataset with 10 observations from 5 conditions each:</p>
<div class="sourceCode" id="cb3"><html><body><pre class="r">set.seed(5)
n = 10
n_condition = 5
ABC =
  tibble(
    condition = factor(rep(c("A","B","C","D","E"), n)),
    response = rnorm(n * 5, c(0,1,2,1,-1), 0.5)
  )</pre></body></html></div>
<p>A snapshot of the data looks like this:</p>
<div class="sourceCode" id="cb4"><html><body><pre class="r"><span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span>(<span class="no">ABC</span>, <span class="fl">10</span>)</pre></body></html></div>
<pre><code>## # A tibble: 10 x 2
##    condition response
##    &lt;fct&gt;        &lt;dbl&gt;
##  1 A           -0.420
##  2 B            1.69 
##  3 C            1.37 
##  4 D            1.04 
##  5 E           -0.144
##  6 A           -0.301
##  7 B            0.764
##  8 C            1.68 
##  9 D            0.857
## 10 E           -0.931</code></pre>
<p>This is a typical tidy format data frame: one observation per row. Graphically:</p>
<div class="sourceCode" id="cb6"><html><body><pre class="r">ABC %&gt;%
  ggplot(aes(y = fct_rev(condition), x = response)) +
  geom_point()</pre></body></html></div>
<p><img src="tidy-rethinking_files/figure-html/unnamed-chunk-4-1.png" width="648"></p>
</div>
<div id="model" class="section level2">
<h2 class="hasAnchor">
<a href="#model" class="anchor"></a>Model</h2>
<p>Let’s fit a hierarchical linear regression model using Hamiltonian Monte Carlo (<code><a href="https://rdrr.io/pkg/rethinking/man/ulam.html">rethinking::ulam()</a></code>). Besides a typical multilevel model for the mean, this model also allows the standard deviation to vary by condition:</p>
<div class="sourceCode" id="cb7"><html><body><pre class="r">m </pre></body></html></div>
<p>The results look like this:</p>
<div class="sourceCode" id="cb8"><html><body><pre class="r"><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span>(<span class="no">m</span>)</pre></body></html></div>
<pre><code>## Inference for Stan model: 7355043b50daed42d51f903beb027f1d.
## 4 chains, each with iter=2000; warmup=1000; thin=1; 
## post-warmup draws per chain=1000, total post-warmup draws=4000.
## 
##                     mean se_mean   sd  2.5%   25%   50%   75% 97.5% n_eff Rhat
## intercept[1]        0.19    0.00 0.15 -0.09  0.10  0.19  0.29  0.50  2709    1
## intercept[2]        1.00    0.00 0.19  0.61  0.89  1.00  1.12  1.37  3509    1
## intercept[3]        1.79    0.00 0.28  1.19  1.62  1.80  1.97  2.32  3219    1
## intercept[4]        1.02    0.00 0.19  0.64  0.90  1.02  1.14  1.39  3000    1
## intercept[5]       -0.90    0.00 0.17 -1.21 -1.00 -0.90 -0.79 -0.54  2878    1
## mu_condition        0.62    0.01 0.58 -0.53  0.29  0.61  0.95  1.76  1827    1
## tau_condition       1.19    0.01 0.47  0.60  0.87  1.08  1.39  2.44  2309    1
## sigma_intercept[1] -0.81    0.00 0.24 -1.23 -0.98 -0.83 -0.66 -0.28  3028    1
## sigma_intercept[2] -0.57    0.00 0.24 -0.99 -0.75 -0.58 -0.41 -0.05  3341    1
## sigma_intercept[3] -0.20    0.00 0.25 -0.62 -0.37 -0.22 -0.06  0.33  3109    1
## sigma_intercept[4] -0.56    0.00 0.24 -0.99 -0.73 -0.58 -0.41 -0.04  2981    1
## sigma_intercept[5] -0.67    0.00 0.25 -1.09 -0.84 -0.69 -0.52 -0.12  3377    1
## lp__               -0.81    0.07 2.65 -6.93 -2.39 -0.39  1.15  3.22  1468    1
## 
## Samples were drawn using NUTS(diag_e) at Mon Jun 01 14:31:35 2020.
## For each parameter, n_eff is a crude measure of effective sample size,
## and Rhat is the potential scale reduction factor on split chains (at 
## convergence, Rhat=1).</code></pre>
</div>
<div id="extracting-draws-from-a-fit-in-tidy-format-using-spread_draws" class="section level2">
<h2 class="hasAnchor">
<a href="#extracting-draws-from-a-fit-in-tidy-format-using-spread_draws" class="anchor"></a>Extracting draws from a fit in tidy-format using <code>spread_draws</code>
</h2>
<div id="extracting-model-variable-indices-into-a-separate-column-in-a-tidy-format-data-frame" class="section level3">
<h3 class="hasAnchor">
<a href="#extracting-model-variable-indices-into-a-separate-column-in-a-tidy-format-data-frame" class="anchor"></a>Extracting model variable indices into a separate column in a tidy format data frame</h3>
<p>Now that we have our results, the fun begins: getting the draws out in a tidy format! The default methods in <code>rethinking</code> for extracting draws from the model do so in a nested format:</p>
<div class="sourceCode" id="cb10"><html><body><pre class="r"><span class="fu"><a href="https://rdrr.io/r/utils/str.html">str</a></span>(<span class="kw pkg">rethinking</span><span class="kw ns">::</span><span class="fu"><a href="https://rdrr.io/pkg/rethinking/man/extract.samples.html">extract.samples</a></span>(<span class="no">m</span>))</pre></body></html></div>
<pre><code>## List of 4
##  $ intercept      : num [1:4000, 1:5] 0.292 0.169 0.137 0.25 0.318 ...
##  $ mu_condition   : num [1:4000(1d)] 0.9545 0.0118 0.9936 0.6169 -0.5484 ...
##  $ tau_condition  : num [1:4000(1d)] 0.9 0.961 0.812 1.037 1.4 ...
##  $ sigma_intercept: num [1:4000, 1:5] -0.925 -0.701 -0.727 -0.642 -0.64 ...
##  - attr(*, "source")= chr "ulam posterior: 4000 samples from m"</code></pre>
<p>The <code>spread_draws()</code> function yields a common format for all model types supported by <code>tidybayes</code>. It lets us instead extract draws into a data frame in tidy format, with a <code>.chain</code> and <code>.iteration</code> column storing the chain and iteration for each row (if available—these columns are <code>NA</code> for <code><a href="https://rdrr.io/pkg/rethinking/man/quap.html">rethinking::quap()</a></code> and <code><a href="https://rdrr.io/pkg/rethinking/man/quap.html">rethinking::map()</a></code> models), a <code>.draw</code> column that uniquely indexes each draw, and the remaining columns corresponding to model variables or variable indices. The <code>spread_draws()</code> function accepts any number of column specifications, which can include names for variables and names for variable indices. For example, we can extract the <code>intercept</code> variable as a tidy data frame, and put the value of its first (and only) index into the <code>condition</code> column, using a syntax that directly echoes how we would specify indices of the <code>intercept</code> variable in the model itself:</p>
<div class="sourceCode" id="cb12"><html><body><pre class="r">m %&gt;%
  spread_draws(intercept[condition]) %&gt;%
  head(10)</pre></body></html></div>
<pre><code>## Warning: `combine()` is deprecated as of dplyr 1.0.0.
## Please use `vctrs::vec_c()` instead.
## This warning is displayed once every 8 hours.
## Call `lifecycle::last_warnings()` to see where this warning was generated.</code></pre>
<pre><code>## # A tibble: 10 x 5
## # Groups:   condition [1]
##    condition intercept .chain .iteration .draw
##        &lt;int&gt;     &lt;dbl&gt;  &lt;int&gt;      &lt;int&gt; &lt;int&gt;
##  1         1    0.0118      1          1     1
##  2         1    0.318       1          2     2
##  3         1   -0.0148      1          3     3
##  4         1    0.299       1          4     4
##  5         1    0.306       1          5     5
##  6         1    0.434       1          6     6
##  7         1    0.161       1          7     7
##  8         1    0.273       1          8     8
##  9         1    0.0731      1          9     9
## 10         1    0.268       1         10    10</code></pre>
</div>
<div id="automatically-converting-columns-and-indices-back-into-their-original-data-types" class="section level3">
<h3 class="hasAnchor">
<a href="#automatically-converting-columns-and-indices-back-into-their-original-data-types" class="anchor"></a>Automatically converting columns and indices back into their original data types</h3>
<p>As-is, the resulting variables don’t know anything about where their indices came from. The index of the <code>intercept</code> variable was originally derived from the <code>condition</code> factor in the <code>ABC</code> data frame. But Stan doesn’t know this: it is just a numeric index to Stan, so the <code>condition</code> column just contains numbers (<code>1, 2, 3, 4, 5</code>) instead of the factor levels these numbers correspond to (<code>"A", "B", "C", "D", "E"</code>).</p>
<p>We can recover this missing type information by passing the model through <code>recover_types()</code> before using <code>spread_draws</code>. In itself <code>recover_types()</code> just returns a copy of the model, with some additional attributes that store the type information from the data frame (or other objects) that you pass to it. This doesn’t have any useful effect by itself, but functions like <code>spread_draws()</code> use this information to convert any column or index back into the data type of the column with the same name in the original data frame. In this example, <code>spread_draws()</code> recognizes that the <code>condition</code> column was a factor with five levels (<code>"A", "B", "C", "D", "E"</code>) in the original data frame, and automatically converts it back into a factor:</p>
<div class="sourceCode" id="cb15"><html><body><pre class="r">m %&gt;%
  recover_types(ABC) %&gt;%
  spread_draws(intercept[condition]) %&gt;%
  head(10)</pre></body></html></div>
<pre><code>## # A tibble: 10 x 5
## # Groups:   condition [1]
##    condition intercept .chain .iteration .draw
##    &lt;fct&gt;         &lt;dbl&gt;  &lt;int&gt;      &lt;int&gt; &lt;int&gt;
##  1 A            0.0118      1          1     1
##  2 A            0.318       1          2     2
##  3 A           -0.0148      1          3     3
##  4 A            0.299       1          4     4
##  5 A            0.306       1          5     5
##  6 A            0.434       1          6     6
##  7 A            0.161       1          7     7
##  8 A            0.273       1          8     8
##  9 A            0.0731      1          9     9
## 10 A            0.268       1         10    10</code></pre>
<p>Because we often want to make multiple separate calls to <code>spread_draws()</code>, it is often convenient to decorate the original model using <code>recover_types()</code> immediately after it has been fit, so we only have to call it once:</p>
<div class="sourceCode" id="cb17"><html><body><pre class="r"><span class="no">m</span> <span class="kw">%&lt;&gt;%</span> <span class="fu">recover_types</span>(<span class="no">ABC</span>)</pre></body></html></div>
<p>Now we can omit the <code>recover_types()</code> call before subsequent calls to <code>spread_draws()</code>.</p>
</div>
</div>
<div id="point-summaries-and-intervals-with-the-point_interval-functions-medianmeanmode_qihdi" class="section level2">
<h2 class="hasAnchor">
<a href="#point-summaries-and-intervals-with-the-point_interval-functions-medianmeanmode_qihdi" class="anchor"></a>Point summaries and intervals with the <code>point_interval</code> functions: <code>[median|mean|mode]_[qi|hdi]</code>
</h2>
<div id="with-simple-variables-wide-format" class="section level3">
<h3 class="hasAnchor">
<a href="#with-simple-variables-wide-format" class="anchor"></a>With simple variables, wide format</h3>
<p><code>tidybayes</code> provides a family of functions for generating point summaries and intervals from draws in a tidy format. These functions follow the naming scheme <code>[median|mean|mode]_[qi|hdi]</code>, for example, <code>median_qi()</code>, <code>mean_qi()</code>, <code>mode_hdi()</code>, and so on. The first name (before the <code>_</code>) indicates the type of point summary, and the second name indicates the type of interval. <code>qi</code> yields a quantile interval (a.k.a. equi-tailed interval, central interval, or percentile interval) and <code>hdi</code> yields a highest density interval. Custom point or interval functions can also be applied using the <code>point_interval()</code> function.</p>
<p>For example, we might extract the draws corresponding to the overall mean (<code>mu_condition</code>) and standard deviation of the condition means (<code>tau_condition</code>):</p>
<div class="sourceCode" id="cb18"><html><body><pre class="r">m %&gt;%
  spread_draws(mu_condition, tau_condition) %&gt;%
  head(10)</pre></body></html></div>
<pre><code>## # A tibble: 10 x 5
##    .chain .iteration .draw mu_condition tau_condition
##     &lt;int&gt;      &lt;int&gt; &lt;int&gt;        &lt;dbl&gt;         &lt;dbl&gt;
##  1      1          1     1       0.434          0.711
##  2      1          2     2       0.0649         1.83 
##  3      1          3     3      -0.315          0.732
##  4      1          4     4       0.458          1.49 
##  5      1          5     5       1.08           1.37 
##  6      1          6     6       0.620          0.931
##  7      1          7     7       0.597          0.972
##  8      1          8     8       0.358          0.982
##  9      1          9     9       0.814          0.927
## 10      1         10    10      -0.180          1.50</code></pre>
<p>Like with <code>spread_draws(intercept[condition])</code>, this gives us a tidy data frame. If we want the median and 95% quantile interval of the variables, we can apply <code>median_qi()</code>:</p>
<div class="sourceCode" id="cb20"><html><body><pre class="r">m %&gt;%
  spread_draws(mu_condition, tau_condition) %&gt;%
  median_qi(mu_condition, tau_condition)</pre></body></html></div>
<pre><code>## # A tibble: 1 x 9
##   mu_condition mu_condition.lo~ mu_condition.up~ tau_condition tau_condition.l~
##          &lt;dbl&gt;            &lt;dbl&gt;            &lt;dbl&gt;         &lt;dbl&gt;            &lt;dbl&gt;
## 1        0.614           -0.531             1.76          1.08            0.596
## # ... with 4 more variables: tau_condition.upper &lt;dbl&gt;, .width &lt;dbl&gt;,
## #   .point &lt;chr&gt;, .interval &lt;chr&gt;</code></pre>
<p><code>median_qi()</code> summarizes each input column using its median. If there are multiple columns to summarize, each gets its own <code>x.lower</code> and <code>x.upper</code> column (for each column <code>x</code>) corresponding to the bounds of the <code>.width</code>% interval. If there is only one column, the names <code>.lower</code> and <code>.upper</code> are used for the interval bounds.</p>
<p>We can specify the columns we want to get medians and intervals from, as above, or if we omit the list of columns, <code>median_qi()</code> will use every column that is not a grouping column or a special column (like <code>.chain</code>, <code>.iteration</code>, or <code>.draw</code>). Thus in the above example, <code>mu_condition</code> and <code>sigma</code> are redundant arguments to <code>median_qi()</code> because they are also the only columns we gathered from the model. So we can simplify the previous code to the following:</p>
<div class="sourceCode" id="cb22"><html><body><pre class="r">m %&gt;%
  spread_draws(mu_condition, tau_condition) %&gt;%
  median_qi()</pre></body></html></div>
<pre><code>## # A tibble: 1 x 9
##   mu_condition mu_condition.lo~ mu_condition.up~ tau_condition tau_condition.l~
##          &lt;dbl&gt;            &lt;dbl&gt;            &lt;dbl&gt;         &lt;dbl&gt;            &lt;dbl&gt;
## 1        0.614           -0.531             1.76          1.08            0.596
## # ... with 4 more variables: tau_condition.upper &lt;dbl&gt;, .width &lt;dbl&gt;,
## #   .point &lt;chr&gt;, .interval &lt;chr&gt;</code></pre>
<p>If you would rather have a long-format list of intervals (often useful for simple summaries), use <code>gather_draws()</code> instead:</p>
<div class="sourceCode" id="cb24"><html><body><pre class="r">m %&gt;%
  gather_draws(mu_condition, tau_condition) %&gt;%
  median_qi()</pre></body></html></div>
<pre><code>## # A tibble: 2 x 7
##   .variable     .value .lower .upper .width .point .interval
##   &lt;chr&gt;          &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;    
## 1 mu_condition   0.614 -0.531   1.76   0.95 median qi       
## 2 tau_condition  1.08   0.596   2.44   0.95 median qi</code></pre>
<p>For more on <code>gather_draws</code>, see <code><a href="http://mjskay.github.io/tidybayes/articles/tidybayes.html">vignette("tidybayes", package = "tidybayes")</a></code>.</p>
</div>
<div id="with-indexed-variables" class="section level3">
<h3 class="hasAnchor">
<a href="#with-indexed-variables" class="anchor"></a>With indexed variables</h3>
<p>When we have a variable with one or more indices, such as <code>intercept</code>, we can apply <code>median_qi()</code> (or other functions in the <code>point_interval()</code> family) as we did before:</p>
<div class="sourceCode" id="cb26"><html><body><pre class="r">m %&gt;%
  spread_draws(intercept[condition]) %&gt;%
  median_qi()</pre></body></html></div>
<pre><code>## # A tibble: 5 x 7
##   condition intercept  .lower .upper .width .point .interval
##   &lt;fct&gt;         &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;    
## 1 A             0.188 -0.0915  0.499   0.95 median qi       
## 2 B             1.00   0.615   1.37    0.95 median qi       
## 3 C             1.80   1.19    2.32    0.95 median qi       
## 4 D             1.02   0.643   1.39    0.95 median qi       
## 5 E            -0.903 -1.21   -0.539   0.95 median qi</code></pre>
<p>How did <code>median_qi</code> know what to aggregate? Data frames returned by <code>spread_draws()</code> are automatically grouped by all index variables you pass to it; in this case, that means it groups by <code>condition</code>. <code>median_qi()</code> respects groups, and calculates the point summaries and intervals within all groups. Then, because no columns were passed to <code>median_qi()</code>, it acts on the only non-special (<code>.</code>-prefixed) and non-group column, <code>intercept</code>. So the above shortened syntax is equivalent to this more verbose call:</p>
<div class="sourceCode" id="cb28"><html><body><pre class="r">m %&gt;%
  spread_draws(intercept[condition]) %&gt;%
  group_by(condition) %&gt;%    # this line not necessary (done automatically by spread_draws)
  median_qi(intercept)</pre></body></html></div>
<pre><code>## # A tibble: 5 x 7
##   condition intercept  .lower .upper .width .point .interval
##   &lt;fct&gt;         &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;    
## 1 A             0.188 -0.0915  0.499   0.95 median qi       
## 2 B             1.00   0.615   1.37    0.95 median qi       
## 3 C             1.80   1.19    2.32    0.95 median qi       
## 4 D             1.02   0.643   1.39    0.95 median qi       
## 5 E            -0.903 -1.21   -0.539   0.95 median qi</code></pre>
<p>When given only a single column, <code>median_qi</code> will use the names <code>.lower</code> and <code>.upper</code> for the lower and upper ends of the intervals.</p>
</div>
</div>
<div id="plotting-points-and-intervals" class="section level2">
<h2 class="hasAnchor">
<a href="#plotting-points-and-intervals" class="anchor"></a>Plotting points and intervals</h2>
<div id="using-geom_pointintervalgeom_pointintervalh" class="section level3">
<h3 class="hasAnchor">
<a href="#using-geom_pointintervalgeom_pointintervalh" class="anchor"></a>Using <code>geom_pointinterval</code>/<code>geom_pointintervalh</code>
</h3>
<p>Plotting medians and intervals is straightforward using the <code>pointinterval</code> geom (or its horizontal version, <code>pointintervalh</code>), which are similar to <code><a href="https://ggplot2.tidyverse.org/reference/geom_linerange.html">ggplot2::geom_pointrange()</a></code> but with sensible defaults for multiple intervals (functionality we will use later):</p>
<div class="sourceCode" id="cb30"><html><body><pre class="r">m %&gt;%
  spread_draws(intercept[condition]) %&gt;%
  median_qi() %&gt;%
  # `geom_pointintervalh` includes `xmin = .lower` and `xmax = .upper` in its default 
  # aesthetics, so we can omit them here
  ggplot(aes(y = fct_rev(condition), x = intercept)) +
  geom_pointintervalh()</pre></body></html></div>
<p><img src="tidy-rethinking_files/figure-html/unnamed-chunk-16-1.png" width="648"></p>
</div>
<div id="using-stat_pointintervalstat_pointintervalh" class="section level3">
<h3 class="hasAnchor">
<a href="#using-stat_pointintervalstat_pointintervalh" class="anchor"></a>Using <code>stat_pointinterval</code>/<code>stat_pointintervalh</code>
</h3>
<p>Rather than summarizing the posterior before calling ggplot, we could also use <code>stat_pointinterval()</code> or <code>stat_pointintervalh()</code> to perform the summary within ggplot:</p>
<div class="sourceCode" id="cb31"><html><body><pre class="r">m %&gt;%
  spread_draws(intercept[condition]) %&gt;%
  ggplot(aes(y = fct_rev(condition), x = intercept)) +
  stat_pointintervalh()</pre></body></html></div>
<p><img src="tidy-rethinking_files/figure-html/unnamed-chunk-17-1.png" width="648"></p>
<p>These functions have <code>.width = c(.66, .95)</code> by default (showing 66% and 95% intervals), but this can be changed by passing a <code>.width</code> argument to <code>stat_pointinterval()</code> / <code>stat_pointintervalh()</code>.</p>
</div>
<div id="intervals-with-posterior-violins-eye-plots-stat_eye-and-stat_eyeh" class="section level3">
<h3 class="hasAnchor">
<a href="#intervals-with-posterior-violins-eye-plots-stat_eye-and-stat_eyeh" class="anchor"></a>Intervals with posterior violins (“eye plots”): <code>stat_eye()</code> and <code>stat_eyeh()</code>
</h3>
<p>The <code>stat_eye()</code> and <code>stat_eyeh()</code> geoms provide a shortcut to generating “eye plots” (combinations of intervals and densities, drawn as violin plots):</p>
<div class="sourceCode" id="cb32"><html><body><pre class="r">m %&gt;%
  spread_draws(intercept[condition]) %&gt;%
  ggplot(aes(y = fct_rev(condition), x = intercept)) +
  stat_eyeh()</pre></body></html></div>
<p><img src="tidy-rethinking_files/figure-html/unnamed-chunk-18-1.png" width="648"></p>
</div>
<div id="intervals-with-posterior-densities-half-eye-plots-stat_halfeyeh" class="section level3">
<h3 class="hasAnchor">
<a href="#intervals-with-posterior-densities-half-eye-plots-stat_halfeyeh" class="anchor"></a>Intervals with posterior densities (“half-eye plots”): <code>stat_halfeyeh()</code>
</h3>
<p>If you prefer densities over violins, you can use <code>stat_halfeyeh()</code>. This example also demonstrates how to change the interval probability (here, to 90% and 50% intervals):</p>
<div class="sourceCode" id="cb33"><html><body><pre class="r">m %&gt;%
  spread_draws(intercept[condition]) %&gt;%
  ggplot(aes(y = fct_rev(condition), x = intercept)) +
  stat_halfeyeh(.width = c(.90, .5))</pre></body></html></div>
<p><img src="tidy-rethinking_files/figure-html/unnamed-chunk-19-1.png" width="648"></p>
<p>Or say you want to annotate portions of the densities in color; the <code>fill</code> aesthetic can vary within a slab in all geoms and stats in the <code>geom_slabinterval()</code> family, including <code>stat_halfeyeh()</code>. For example, if you want to annotate a domain-specific region of practical equivalence (ROPE), you could do something like this:</p>
<div class="sourceCode" id="cb34"><html><body><pre class="r">m %&gt;%
  spread_draws(intercept[condition]) %&gt;%
  ggplot(aes(y = fct_rev(condition), x = intercept, fill = stat(abs(x) &lt; .8))) +
  stat_halfeyeh() +
  geom_vline(xintercept = c(-.8, .8), linetype = "dashed") +
  scale_fill_manual(values = c("gray80", "skyblue"))</pre></body></html></div>
<p><img src="tidy-rethinking_files/figure-html/unnamed-chunk-20-1.png" width="648"></p>
</div>
<div id="other-visualizations-of-distributions-stat_slabinterval" class="section level3">
<h3 class="hasAnchor">
<a href="#other-visualizations-of-distributions-stat_slabinterval" class="anchor"></a>Other visualizations of distributions: <code>stat_slabinterval()</code>
</h3>
<p>There are a variety of additional stats for visualizing distributions in the <code>geom_slabinterval()</code> family of stats and geoms:</p>
<p><img src="slabinterval_family.png" width="700" alt="The slabinterval family of geoms and stats"></p>
<p>See <code><a href="http://mjskay.github.io/tidybayes/articles/slabinterval.html">vignette("slabinterval", package = "tidybayes")</a></code> for an overview.</p>
</div>
<div id="plotting-posteriors-as-quantile-dotplots" class="section level3">
<h3 class="hasAnchor">
<a href="#plotting-posteriors-as-quantile-dotplots" class="anchor"></a>Plotting posteriors as quantile dotplots</h3>
<p>Intervals are nice if the alpha level happens to line up with whatever decision you are trying to make, but getting a shape of the posterior is better (hence eye plots, above). On the other hand, making inferences from density plots is imprecise (estimating the area of one shape as a proportion of another is a hard perceptual task). Reasoning about probability in frequency formats is easier, motivating <a href="https://github.com/mjskay/when-ish-is-my-bus/blob/master/quantile-dotplots.md">quantile dotplots</a> (<a href="https://doi.org/10.1145/2858036.2858558">Kay et al. 2016</a>, <a href="https://doi.org/10.1145/3173574.3173718">Fernandes et al. 2018</a>), which also allow precise estimation of arbitrary intervals (down to the dot resolution of the plot, 100 in the example below).</p>
<p>Within the slabinterval family of geoms in tidybayes is the <code>dots</code> and <code>dotsinterval</code> family, which automatically determine appropriate bin sizes for dotplots and can calculate quantiles from samples to construct quantile dotplots. <code>stat_dotsh()</code> is the horizontal variant designed for use on samples:</p>
<div class="sourceCode" id="cb35"><html><body><pre class="r">m %&gt;%
  spread_draws(intercept[condition]) %&gt;%
  ggplot(aes(x = intercept, y = fct_rev(condition))) +
  stat_dotsh(quantiles = 100)</pre></body></html></div>
<p><img src="tidy-rethinking_files/figure-html/unnamed-chunk-21-1.png" width="648"></p>
<p>The idea is to get away from thinking about the posterior as indicating one canonical point or interval, but instead to represent it as (say) 100 approximately equally likely points.</p>
</div>
</div>
<div id="combining-variables-with-different-indices-in-a-single-tidy-format-data-frame" class="section level2">
<h2 class="hasAnchor">
<a href="#combining-variables-with-different-indices-in-a-single-tidy-format-data-frame" class="anchor"></a>Combining variables with different indices in a single tidy format data frame</h2>
<p><code>spread_draws()</code> supports extracting variables that have different indices. It automatically matches up indices with the same name, and duplicates values as necessary to produce one row per all combination of levels of all indices. For example, we might want to calculate the difference between each condition’s intercept and the overall mean. To do that, we can extract draws from the overall mean (<code>mu_condition</code>) and all condition means (<code>intercept[condition]</code>:</p>
<div class="sourceCode" id="cb36"><html><body><pre class="r">m %&gt;% 
  spread_draws(mu_condition, intercept[condition]) %&gt;%
  head(10)</pre></body></html></div>
<pre><code>## # A tibble: 10 x 6
## # Groups:   condition [5]
##    .chain .iteration .draw mu_condition condition intercept
##     &lt;int&gt;      &lt;int&gt; &lt;int&gt;        &lt;dbl&gt; &lt;fct&gt;         &lt;dbl&gt;
##  1      1          1     1       0.434  A            0.0118
##  2      1          1     1       0.434  B            0.910 
##  3      1          1     1       0.434  C            1.83  
##  4      1          1     1       0.434  D            0.620 
##  5      1          1     1       0.434  E           -1.07  
##  6      1          2     2       0.0649 A            0.318 
##  7      1          2     2       0.0649 B            0.789 
##  8      1          2     2       0.0649 C            1.22  
##  9      1          2     2       0.0649 D            0.788 
## 10      1          2     2       0.0649 E           -1.24</code></pre>
<p>Within each draw, <code>mu_condition</code> is repeated as necessary to correspond to every index of <code>intercept</code>. Thus, <code><a href="https://dplyr.tidyverse.org/reference/mutate.html">dplyr::mutate()</a></code> can be used to take the differences over all rows, then we can summarize with <code>median_qi()</code>:</p>
<div class="sourceCode" id="cb38"><html><body><pre class="r">m %&gt;%
  spread_draws(mu_condition, intercept[condition]) %&gt;%
  mutate(condition_offset = intercept - mu_condition) %&gt;%
  median_qi(condition_offset)</pre></body></html></div>
<pre><code>## # A tibble: 5 x 7
##   condition condition_offset   .lower .upper .width .point .interval
##   &lt;fct&gt;                &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;    
## 1 A                   -0.418 -1.62     0.729   0.95 median qi       
## 2 B                    0.381 -0.826    1.59    0.95 median qi       
## 3 C                    1.16  -0.00460  2.47    0.95 median qi       
## 4 D                    0.393 -0.768    1.61    0.95 median qi       
## 5 E                   -1.50  -2.73    -0.322   0.95 median qi</code></pre>
<p><code>median_qi()</code> uses tidy evaluation (see <code>vignette("tidy-evaluation", package = "rlang")</code>), so it can take column expressions, not just column names. Thus, we can simplify the above example by moving the calculation of <code>condition_mean</code> from <code>mutate()</code> into <code>median_qi()</code>:</p>
<div class="sourceCode" id="cb40"><html><body><pre class="r">m %&gt;%
  spread_draws(mu_condition, intercept[condition]) %&gt;%
  median_qi(intercept - mu_condition)</pre></body></html></div>
<pre><code>## # A tibble: 5 x 7
##   condition `intercept - mu_condition`   .lower .upper .width .point .interval
##   &lt;fct&gt;                          &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;    
## 1 A                             -0.418 -1.62     0.729   0.95 median qi       
## 2 B                              0.381 -0.826    1.59    0.95 median qi       
## 3 C                              1.16  -0.00460  2.47    0.95 median qi       
## 4 D                              0.393 -0.768    1.61    0.95 median qi       
## 5 E                             -1.50  -2.73    -0.322   0.95 median qi</code></pre>
</div>
<div id="posterior-fits" class="section level2">
<h2 class="hasAnchor">
<a href="#posterior-fits" class="anchor"></a>Posterior fits</h2>
<p>Rather than calculating conditional means manually from model parameters, we could use <code>add_fitted_draws</code>, which is analogous to <code><a href="https://rdrr.io/pkg/rethinking/man/link.html">rethinking::link</a></code> (giving posterior draws from the model’s linear predictor), but uses a tidy data format. We can combine it with <code><a href="https://modelr.tidyverse.org/reference/data_grid.html">modelr::data_grid</a></code> to first generate a grid describing the fits we want, then transform that grid into a long-format data frame of draws from posterior fits:</p>
<div class="sourceCode" id="cb42"><html><body><pre class="r">ABC %&gt;%
  data_grid(condition) %&gt;%
  add_fitted_draws(m) %&gt;%
  head(10)</pre></body></html></div>
<pre><code>## # A tibble: 10 x 4
## # Groups:   condition, .row [1]
##    condition  .row .draw .value
##    &lt;fct&gt;     &lt;int&gt; &lt;dbl&gt;  &lt;dbl&gt;
##  1 A             1   939 0.292 
##  2 A             1   831 0.169 
##  3 A             1   979 0.137 
##  4 A             1   777 0.250 
##  5 A             1   972 0.318 
##  6 A             1   596 0.151 
##  7 A             1    85 0.0944
##  8 A             1   730 0.181 
##  9 A             1   902 0.288 
## 10 A             1   184 0.434</code></pre>
<p>This approach can be less error-prone if we change the parameterization of the model later, since <code>rethinking</code> will figure out how to calculate the linear predictor for us (rather than us having to do it manually, a calculation which changes depending on the model parameterization).</p>
<p>Then we can plot the output with <code>stat_pointintervalh()</code>:</p>
<div class="sourceCode" id="cb44"><html><body><pre class="r">ABC %&gt;%
  data_grid(condition) %&gt;%
  add_fitted_draws(m) %&gt;%
  ggplot(aes(x = .value, y = fct_rev(condition))) +
  stat_pointintervalh(.width = c(.66, .95))</pre></body></html></div>
<p><img src="tidy-rethinking_files/figure-html/unnamed-chunk-26-1.png" width="648"></p>
</div>
<div id="posterior-predictions" class="section level2">
<h2 class="hasAnchor">
<a href="#posterior-predictions" class="anchor"></a>Posterior predictions</h2>
<p>Where <code>add_fitted_draws</code> is analogous to <code><a href="https://rdrr.io/pkg/rethinking/man/link.html">rethinking::link()</a></code>, <code>add_predicted_draws</code> is analogous to <code><a href="https://rdrr.io/pkg/rethinking/man/sim.html">rethinking::sim()</a></code>, giving draws from the posterior predictive distribution.</p>
<p>Here is an example of posterior predictive distributions plotted using <code>stat_slabh()</code>:</p>
<div class="sourceCode" id="cb45"><html><body><pre class="r">ABC %&gt;%
  data_grid(condition) %&gt;%
  add_predicted_draws(m) %&gt;%
  ggplot(aes(x = .prediction, y = condition)) +
  stat_slabh()</pre></body></html></div>
<p><img src="tidy-rethinking_files/figure-html/unnamed-chunk-27-1.png" width="648"></p>
<p>We could also use <code><a href="http://mjskay.github.io/tidybayes/reference/stat_interval.html">tidybayes::stat_intervalh()</a></code> to plot predictive bands alongside the data:</p>
<div class="sourceCode" id="cb46"><html><body><pre class="r">ABC %&gt;%
  data_grid(condition) %&gt;%
  add_predicted_draws(m) %&gt;%
  ggplot(aes(y = condition, x = .prediction)) +
  stat_intervalh(.width = c(.50, .80, .95, .99)) +
  geom_point(aes(x = response), data = ABC) +
  scale_color_brewer()</pre></body></html></div>
<p><img src="tidy-rethinking_files/figure-html/unnamed-chunk-28-1.png" width="648"></p>
<p>Altogether, data, posterior predictions, and posterior distributions of the means:</p>
<div class="sourceCode" id="cb47"><html><body><pre class="r">grid = ABC %&gt;%
  data_grid(condition)

fits = grid %&gt;%
  add_fitted_draws(m)

preds = grid %&gt;%
  add_predicted_draws(m)

ABC %&gt;%
  ggplot(aes(y = condition, x = response)) +
  stat_intervalh(aes(x = .prediction), data = preds) +
  stat_pointintervalh(aes(x = .value), data = fits, .width = c(.66, .95), position = position_nudge(y = -0.3)) +
  geom_point() +
  scale_color_brewer()</pre></body></html></div>
<p><img src="tidy-rethinking_files/figure-html/unnamed-chunk-29-1.png" width="648"></p>
</div>
<div id="posterior-predictions-kruschke-style" class="section level2">
<h2 class="hasAnchor">
<a href="#posterior-predictions-kruschke-style" class="anchor"></a>Posterior predictions, Kruschke-style</h2>
<p>The above approach to posterior predictions integrates over the parameter uncertainty to give a single posterior predictive distribution. Another approach, often used by John Kruschke in his book <a href="https://sites.google.com/site/doingbayesiandataanalysis/">Doing Bayesian Data Analysis</a>, is to attempt to show both the predictive uncertainty and the parameter uncertainty simultaneously by showing several possible predictive distributions implied by the posterior.</p>
<p>We can do this pretty easily by asking for the distributional parameters for a given prediction implied by the posterior. These are the link-level linear predictors returned by <code><a href="https://rdrr.io/pkg/rethinking/man/link.html">rethinking::link()</a></code>; in <code>tidybayes</code> we follow the terminology of the <code>brms</code> package and calls these distributional regression parameters. In our model, these are the <code>mu</code> and <code>sigma</code> parameters. We can access these explicitly by setting <code>dpar = c("mu", "sigma")</code> in <code>add_fitted_draws</code>. Rather than specifying the parameters explicitly, you can also just set <code>dpar = TRUE</code> to get draws from all distributional parameters in a model. Then, we can select a small number of draws using <code>tidybyaes::sample_draws()</code> and then use <code>stat_dist_slabh()</code> to visualize each predictive distribution implied by the values of <code>mu</code> and <code>sigma</code>:</p>
<div class="sourceCode" id="cb48"><html><body><pre class="r">ABC %&gt;%
  data_grid(condition) %&gt;%
  add_fitted_draws(m, dpar = c("mu", "sigma")) %&gt;%
  sample_draws(30) %&gt;%
  ggplot(aes(y = condition)) +
  stat_dist_slabh(aes(dist = "norm", arg1 = mu, arg2 = sigma), 
    slab_color = "gray65", alpha = 1/10, fill = NA
  ) +
  geom_point(aes(x = response), data = ABC, shape = 21, fill = "#9ECAE1", size = 2)</pre></body></html></div>
<p><img src="tidy-rethinking_files/figure-html/unnamed-chunk-30-1.png" width="648"></p>
<p>For a more detailed description of these charts (and some useful variations on them), see <a href="https://solomonkurz.netlify.com/post/make-rotated-gaussians-kruschke-style/">Solomon Kurz’s excellent blog post on the topic</a>.</p>
<p>We could even combine the Kruschke-style plots of predictive distributions with half-eyes showing the posterior means:</p>
<div class="sourceCode" id="cb49"><html><body><pre class="r">ABC %&gt;%
  data_grid(condition) %&gt;%
  add_fitted_draws(m, dpar = c("mu", "sigma")) %&gt;%
  ggplot(aes(x = condition)) +
  stat_dist_slab(aes(dist = "norm", arg1 = mu, arg2 = sigma), 
    slab_color = "gray65", alpha = 1/10, fill = NA, data = . %&gt;% sample_draws(30), scale = .5
  ) +
  stat_halfeye(aes(y = .value), side = "bottom", scale = .5) +
  geom_point(aes(y = response), data = ABC, shape = 21, fill = "#9ECAE1", size = 2, position = position_nudge(x = -.2))</pre></body></html></div>
<p><img src="tidy-rethinking_files/figure-html/unnamed-chunk-31-1.png" width="648"></p>
</div>
<div id="fitprediction-curves" class="section level2">
<h2 class="hasAnchor">
<a href="#fitprediction-curves" class="anchor"></a>Fit/prediction curves</h2>
<p>To demonstrate drawing fit curves with uncertainty, let’s fit a slightly naive model to part of the <code>mtcars</code> dataset. First, we’ll make the cylinder count a factor so that we can index other variables in the model by it:</p>
<div class="sourceCode" id="cb50"><html><body><pre class="r">mtcars_clean = mtcars %&gt;%
  mutate(cyl = factor(cyl))</pre></body></html></div>
<p>Then, we’ll fit a naive linear model where cars with different numbers of cylinders each get their own linear relationship between horsepower and miles per gallon:</p>
<div class="sourceCode" id="cb51"><html><body><pre class="r">m_mpg = ulam(alist(
    mpg ~ normal(mu, sigma),
  
    mu </pre></body></html></div>
<p>We can draw fit curves with probability bands using <code>add_fitted_draws()</code> with <code><a href="http://mjskay.github.io/tidybayes/reference/stat_lineribbon.html">tidybayes::stat_lineribbon()</a></code>:</p>
<div class="sourceCode" id="cb52"><html><body><pre class="r">mtcars_clean %&gt;%
  group_by(cyl) %&gt;%
  data_grid(hp = seq_range(hp, n = 51)) %&gt;%
  add_fitted_draws(m_mpg) %&gt;%
  ggplot(aes(x = hp, y = mpg, color = cyl)) +
  stat_lineribbon(aes(y = .value)) +
  geom_point(data = mtcars_clean) +
  scale_fill_brewer(palette = "Greys") +
  scale_color_brewer(palette = "Set2")</pre></body></html></div>
<p><img src="tidy-rethinking_files/figure-html/unnamed-chunk-33-1.png" width="648"></p>
<p>Or we can sample a reasonable number of fit lines (say 100) and overplot them:</p>
<div class="sourceCode" id="cb53"><html><body><pre class="r">mtcars_clean %&gt;%
  group_by(cyl) %&gt;%
  data_grid(hp = seq_range(hp, n = 101)) %&gt;%
  add_fitted_draws(m_mpg, n = 100) %&gt;%
  ggplot(aes(x = hp, y = mpg, color = cyl)) +
  geom_line(aes(y = .value, group = paste(cyl, .draw)), alpha = .1) +
  geom_point(data = mtcars_clean) +
  scale_color_brewer(palette = "Dark2")</pre></body></html></div>
<p><img src="tidy-rethinking_files/figure-html/unnamed-chunk-34-1.png" width="648"></p>
<p>Or we can create animated <a href="https://mucollective.northwestern.edu/project/hops-trends">hypothetical outcome plots (HOPs)</a> of fit lines:</p>
<div class="sourceCode" id="cb54"><html><body><pre class="r">set.seed(123456)
# to keep the example small we use 20 frames, 
# but something like 100 would be better
ndraws = 20

p = mtcars_clean %&gt;%
  group_by(cyl) %&gt;%
  data_grid(hp = seq_range(hp, n = 101)) %&gt;%
  add_fitted_draws(m_mpg, n = ndraws) %&gt;%
  ggplot(aes(x = hp, y = mpg, color = cyl)) +
  geom_line(aes(y = .value, group = paste(cyl, .draw))) +
  geom_point(data = mtcars_clean) +
  scale_color_brewer(palette = "Dark2") +
  transition_states(.draw, 0, 1) +
  shadow_mark(future = TRUE, color = "gray50", alpha = 1/20)

animate(p, nframes = ndraws, fps = 2.5, width = 432, height = 288, res = 96, dev = "png", type = "cairo")</pre></body></html></div>
<p><img src="tidy-rethinking_files/figure-html/unnamed-chunk-35-1.gif"><!-- --></p>
<p>Or, for posterior predictions (instead of fits), we can go back to probability bands:</p>
<div class="sourceCode" id="cb55"><html><body><pre class="r">mtcars_clean %&gt;%
  group_by(cyl) %&gt;%
  data_grid(hp = seq_range(hp, n = 101)) %&gt;%
  add_predicted_draws(m_mpg) %&gt;%
  ggplot(aes(x = hp, y = mpg, color = cyl, fill = cyl)) +
  stat_lineribbon(aes(y = .prediction), .width = c(.95, .80, .50), alpha = 1/4) +
  geom_point(data = mtcars_clean) +
  scale_fill_brewer(palette = "Set2") +
  scale_color_brewer(palette = "Dark2")</pre></body></html></div>
<p><img src="tidy-rethinking_files/figure-html/unnamed-chunk-36-1.png" width="648"></p>
<p>This gets difficult to judge by group, so probably better to facet into multiple plots. Fortunately, since we are using ggplot, that functionality is built in:</p>
<div class="sourceCode" id="cb56"><html><body><pre class="r">mtcars_clean %&gt;%
  group_by(cyl) %&gt;%
  data_grid(hp = seq_range(hp, n = 101)) %&gt;%
  add_predicted_draws(m_mpg) %&gt;%
  ggplot(aes(x = hp, y = mpg)) +
  stat_lineribbon(aes(y = .prediction), .width = c(.95, .8, .5), color = brewer.pal(5, "Blues")[[5]]) +
  geom_point(data = mtcars_clean) +
  scale_fill_brewer() +
  facet_grid(. ~ cyl, space = "free_x", scales = "free_x")</pre></body></html></div>
<p><img src="tidy-rethinking_files/figure-html/unnamed-chunk-37-1.png" width="648"></p>
</div>
<div id="comparing-levels-of-a-factor" class="section level2">
<h2 class="hasAnchor">
<a href="#comparing-levels-of-a-factor" class="anchor"></a>Comparing levels of a factor</h2>
<p>If we wish compare the means from each condition, <code><a href="http://mjskay.github.io/tidybayes/reference/compare_levels.html">tidybayes::compare_levels()</a></code> facilitates comparisons of the value of some variable across levels of a factor. By default it computes all pairwise differences.</p>
<p>Let’s demonstrate <code><a href="http://mjskay.github.io/tidybayes/reference/compare_levels.html">tidybayes::compare_levels()</a></code> with another plotting geom, <code><a href="http://mjskay.github.io/tidybayes/reference/stat_sample_slabinterval.html">tidybayes::stat_halfeyeh()</a></code>, which gives horizontal “half-eye” plots, combining intervals with a density plot:</p>
<div class="sourceCode" id="cb57"><html><body><pre class="r">#N.B. the syntax for compare_levels is experimental and may change
m %&gt;%
  spread_draws(intercept[condition]) %&gt;%
  compare_levels(intercept, by = condition) %&gt;%
  ggplot(aes(y = condition, x = intercept)) +
  stat_halfeyeh()</pre></body></html></div>
<p><img src="tidy-rethinking_files/figure-html/unnamed-chunk-38-1.png" width="648"></p>
<p>If you prefer “caterpillar” plots, ordered by something like the mean of the difference, you can reorder the factor before plotting:</p>
<div class="sourceCode" id="cb58"><html><body><pre class="r">#N.B. the syntax for compare_levels is experimental and may change
m %&gt;%
  spread_draws(intercept[condition]) %&gt;%
  compare_levels(intercept, by = condition) %&gt;%
  ungroup() %&gt;%
  mutate(condition = reorder(condition, intercept)) %&gt;%
  ggplot(aes(y = condition, x = intercept)) +
  stat_halfeyeh() +
  geom_vline(xintercept = 0, linetype = "dashed") </pre></body></html></div>
<p><img src="tidy-rethinking_files/figure-html/unnamed-chunk-39-1.png" width="648"></p>
</div>
<div id="ordinal-models" class="section level2">
<h2 class="hasAnchor">
<a href="#ordinal-models" class="anchor"></a>Ordinal models</h2>
<p>The <code><a href="https://rdrr.io/pkg/rethinking/man/link.html">rethinking::link()</a></code> function for ordinal models returns draws from the latent linear predictor (in contrast to the <code><a href="https://rdrr.io/pkg/brms/man/fitted.brmsfit.html">brms::fitted.brmsfit</a></code> function for ordinal and multinomial regression models in brms, which returns multiple variables for each draw: one for each outcome category, see the ordinal regression examples in <code><a href="http://mjskay.github.io/tidybayes/articles/tidy-brms.html">vignette("tidy-brms", package = "tidybayes")</a></code>). The philosophy of <code>tidybayes</code> is to tidy whatever format is output by a model, so in keeping with that philosophy, when applied to ordinal <code>rethinking</code> models, <code>add_fitted_draws</code> simply returns draws from the latent linear predictor. This means we have to do a bit more work to recover category probabilities.</p>
<div id="ordinal-model-with-continuous-predictor" class="section level3">
<h3 class="hasAnchor">
<a href="#ordinal-model-with-continuous-predictor" class="anchor"></a>Ordinal model with continuous predictor</h3>
<p>We’ll fit a model using the <code>mtcars</code> dataset that predicts the number of cylinders in a car given the car’s mileage (in miles per gallon). While this is a little backwards causality-wise (presumably the number of cylinders causes the mileage, if anything), that does not mean this is not a fine prediction task (I could probably tell someone who knows something about cars the MPG of a car and they could do reasonably well at guessing the number of cylinders in the engine). Here’s a simple ordinal regression model:</p>
<div class="sourceCode" id="cb59"><html><body><pre class="r">m_cyl = ulam(alist(
    cyl ~ dordlogit(phi, cutpoint),
    phi </pre></body></html></div>
<p>Here is a plot of the link-level fit:</p>
<div class="sourceCode" id="cb60"><html><body><pre class="r">mtcars_clean %&gt;%
  data_grid(mpg = seq_range(mpg, n = 101)) %&gt;%
  add_fitted_draws(m_cyl) %&gt;%
  ggplot(aes(x = mpg, y = .value)) +
  stat_lineribbon(color = "red") +
  scale_fill_brewer(palette = "Greys")</pre></body></html></div>
<p><img src="tidy-rethinking_files/figure-html/unnamed-chunk-40-1.png" width="648"></p>
<p>This can be hard to interpret. To turn this into predicted probabilities on a per-category basis, we have to use the fact that an ordinal logistic regression defines the probability of an outcome in category <span class="math inline">\(j\)</span> <strong>or less</strong> as:</p>
<p><span class="math display">\[
\textrm{logit}\left[Pr(Y\le j)\right] = \textrm{cutpoint}_j - \beta x
\]</span></p>
<p>Thus, the probability of category <span class="math inline">\(j\)</span> is:</p>
<p><span class="math display">\[
\begin{align}
Pr(Y = j) &amp;= Pr(Y \le j) - Pr(Y \le j - 1)\\
&amp;= \textrm{logit}^{-1}(\textrm{cutpoint}_j - \beta x) - \textrm{logit}^{-1}(\textrm{cutpoint}_{j-1} - \beta x)
\end{align}
\]</span> To derive these values, we need two things:</p>
<ul>
<li><p>The <span class="math inline">\(\textrm{cutpoint}_j\)</span> values. These are threshold parameters fitted by the model. For convenience, if there are <span class="math inline">\(k\)</span> levels, we will take <span class="math inline">\(\textrm{cutpoint}_k = +\infty\)</span>, since the probability of being in the top level or below it is 1.</p></li>
<li><p>The <span class="math inline">\(\beta x\)</span> values. These are just the <code>.value</code> column returned by <code>add_fitted_draws()</code>.</p></li>
</ul>
<p>The cutpoints in this model are defined by the <code>cutpoints[j]</code> parameters. We can We can see those parameters in the list of variables in the model:</p>
<div class="sourceCode" id="cb61"><html><body><pre class="r"><span class="fu">get_variables</span>(<span class="no">m_cyl</span>)</pre></body></html></div>
<pre><code>##  [1] "b_mpg"         "cutpoint[1]"   "cutpoint[2]"   "lp__"         
##  [5] "accept_stat__" "stepsize__"    "treedepth__"   "n_leapfrog__" 
##  [9] "divergent__"   "energy__"</code></pre>
<div class="sourceCode" id="cb63"><html><body><pre class="r">cutpoints = m_cyl %&gt;%
  recover_types(mtcars_clean) %&gt;%
  spread_draws(cutpoint[cyl])

# define the last cutpoint
last_cutpoint = tibble(
  .draw = 1:max(cutpoints$.draw),
  cyl = "8",
  cutpoint = Inf
)

cutpoints = bind_rows(cutpoints, last_cutpoint) %&gt;%
  # define the previous cutpoint (cutpoint_{j-1})
  group_by(.draw) %&gt;%
  arrange(cyl) %&gt;%
  mutate(prev_cutpoint = lag(cutpoint, default = -Inf))

# the resulting cutpoints look like this:
cutpoints %&gt;% 
  group_by(cyl) %&gt;%
  median_qi(cutpoint, prev_cutpoint)</pre></body></html></div>
<pre><code>## # A tibble: 3 x 10
##   cyl   cutpoint cutpoint.lower cutpoint.upper prev_cutpoint prev_cutpoint.l~
##   &lt;chr&gt;    &lt;dbl&gt;          &lt;dbl&gt;          &lt;dbl&gt;         &lt;dbl&gt;            &lt;dbl&gt;
## 1 4        -24.3          -44.9          -13.2        -Inf             -Inf  
## 2 6        -20.4          -37.9          -10.7         -24.3            -44.9
## 3 8        Inf            Inf            Inf           -20.4            -37.9
## # ... with 4 more variables: prev_cutpoint.upper &lt;dbl&gt;, .width &lt;dbl&gt;,
## #   .point &lt;chr&gt;, .interval &lt;chr&gt;</code></pre>
<p>Given the data frame of cutpoints and the latent linear predictor, we can more-or-less directly write the formula for the probability of each category conditional on mpg into our code:</p>
<div class="sourceCode" id="cb65"><html><body><pre class="r">fitted_cyl_probs = mtcars_clean %&gt;%
  data_grid(mpg = seq_range(mpg, n = 101)) %&gt;%
  add_fitted_draws(m_cyl) %&gt;%
  inner_join(cutpoints, by = ".draw") %&gt;%
  mutate(`P(cyl | mpg)` = 
    # this part is logit^-1(cutpoint_j - beta*x) - logit^-1(cutpoint_{j-1} - beta*x)
    plogis(cutpoint - .value) - plogis(prev_cutpoint - .value)
  )

fitted_cyl_probs %&gt;%
  head(10)</pre></body></html></div>
<pre><code>## # A tibble: 10 x 10
## # Groups:   mpg, .row [1]
##      mpg  .row .draw .value cyl   cutpoint .chain .iteration prev_cutpoint
##    &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt;  &lt;int&gt;      &lt;int&gt;         &lt;dbl&gt;
##  1  10.4     1   595  -7.21 4        -15.4      1        595        -Inf  
##  2  10.4     1   595  -7.21 6        -12.6      1        595         -15.4
##  3  10.4     1   595  -7.21 8        Inf       NA         NA         -12.6
##  4  10.4     1  1000  -9.95 4        -21.2      1       1000        -Inf  
##  5  10.4     1  1000  -9.95 6        -17.5      1       1000         -21.2
##  6  10.4     1  1000  -9.95 8        Inf       NA         NA         -17.5
##  7  10.4     1   162 -11.5  4        -22.4      1        162        -Inf  
##  8  10.4     1   162 -11.5  6        -19.6      1        162         -22.4
##  9  10.4     1   162 -11.5  8        Inf       NA         NA         -19.6
## 10  10.4     1   356 -14.5  4        -29.8      1        356        -Inf  
## # ... with 1 more variable: `P(cyl | mpg)` &lt;dbl&gt;</code></pre>
<p>Then we can plot those probability curves against the datset:</p>
<div class="sourceCode" id="cb67"><html><body><pre class="r">data_plot = mtcars_clean %&gt;%
  ggplot(aes(x = mpg, y = cyl, color = cyl)) +
  geom_point() +
  scale_color_brewer(palette = "Dark2", name = "cyl")

fit_plot = fitted_cyl_probs %&gt;%
  ggplot(aes(x = mpg, y = `P(cyl | mpg)`, color = cyl)) +
  stat_lineribbon(aes(fill = cyl), alpha = 1/5) +
  scale_color_brewer(palette = "Dark2") +
  scale_fill_brewer(palette = "Dark2")

plot_grid(ncol = 1, align = "v",
  data_plot,
  fit_plot
)</pre></body></html></div>
<p><img src="tidy-rethinking_files/figure-html/unnamed-chunk-44-1.png" width="648"></p>
<p>The above display does not let you see the correlation between <code>P(cyl|mpg)</code> for different values of <code>cyl</code> at a particular value of <code>mpg</code>. For example, in the portion of the posterior where <code>P(cyl = 6|mpg = 20)</code> is high, <code>P(cyl = 4|mpg = 20)</code> and <code>P(cyl = 8|mpg = 20)</code> must be low (since these must add up to 1).</p>
<p>One way to see this correlation might be to employ <a href="https://doi.org/10.1371/journal.pone.0142444">hypothetical outcome plots (HOPs)</a> just for the fit line, “detaching” it from the ribbon (another alternative would be to use HOPs on top of line ensembles, as demonstrated earlier in this document). By employing animation, you can see how the lines move in tandem or opposition to each other, revealing some patterns in how they are correlated:</p>
<div class="sourceCode" id="cb68"><html><body><pre class="r">ndraws = 100

p = fitted_cyl_probs %&gt;%
  ggplot(aes(x = mpg, y = `P(cyl | mpg)`, color = cyl)) +
  # we remove the `.draw` column from the data for stat_lineribbon so that the same ribbons
  # are drawn on every frame (since we use .draw to determine the transitions below)
  stat_lineribbon(aes(fill = cyl), alpha = 1/5, color = NA, data = . %&gt;% select(-.draw)) +
  # we use sample_draws to subsample at the level of geom_line (rather than for the full dataset
  # as in previous HOPs examples) because we need the full set of draws for stat_lineribbon above
  geom_line(aes(group = paste(.draw, cyl)), size = 1, data = . %&gt;% sample_draws(ndraws)) +
  scale_color_brewer(palette = "Dark2") +
  scale_fill_brewer(palette = "Dark2") +
  transition_manual(.draw)

animate(p, nframes = ndraws, fps = 2.5, width = 576, height = 192, res = 96, dev = "png", type = "cairo")</pre></body></html></div>
<p><img src="tidy-rethinking_files/figure-html/unnamed-chunk-45-1.gif"><!-- --></p>
<p>Notice how the lines move together, and how they move up or down together or in opposition due to their correlation.</p>
<p>While talking about the mean for an ordinal distribution often does not make sense, in this particular case one could argue that the expected number of cylinders for a car given its miles per gallon is a meaningful quantity. We could plot the posterior distribution for the average number of cylinders for a car given a particular miles per gallon as follows:</p>
<p><span class="math display">\[
\textrm{E}[\textrm{cyl}|\textrm{mpg}=m] = \sum_{c \in \{4,6,8\}} c\cdot \textrm{P}(\textrm{cyl}=c|\textrm{mpg}=m)
\]</span></p>
<p>We can use the above formula to derive a posterior distribution for <span class="math inline">\(\textrm{E}[\textrm{cyl}|\textrm{mpg}=m]\)</span> from the model. The <code>fitted_cyl_probs</code> data frame above gives us the posterior distribution for <span class="math inline">\(\textrm{P}(\textrm{cyl}=c|\textrm{mpg}=m)\)</span>. Thus, we can group within <code>.draw</code> and then use <code>summarise</code> to calculate the expected value:</p>
<div class="sourceCode" id="cb69"><html><body><pre class="r">label_data_function = . %&gt;% 
  ungroup() %&gt;%
  filter(mpg == quantile(mpg, .47)) %&gt;%
  summarise_if(is.numeric, mean)

data_plot_with_mean = fitted_cyl_probs %&gt;%
  sample_draws(100) %&gt;%
  # convert cylinder values back into numbers
  mutate(cyl = as.numeric(as.character(cyl))) %&gt;%
  group_by(mpg, .draw) %&gt;%
  # calculate expected cylinder value
  summarise(cyl = sum(cyl * `P(cyl | mpg)`)) %&gt;%
  ggplot(aes(x = mpg, y = cyl)) +
  geom_line(aes(group = .draw), alpha = 5/100) +
  geom_point(aes(y = as.numeric(as.character(cyl)), fill = cyl), data = mtcars_clean, shape = 21, size = 2) +
  geom_text(aes(x = mpg + 4), label = "E[cyl | mpg]", data = label_data_function, hjust = 0) +
  geom_segment(aes(yend = cyl, xend = mpg + 3.9), data = label_data_function) +
  scale_fill_brewer(palette = "Set2", name = "cyl")

plot_grid(ncol = 1, align = "v",
  data_plot_with_mean,
  fit_plot
)</pre></body></html></div>
<p><img src="tidy-rethinking_files/figure-html/unnamed-chunk-46-1.png" width="648"></p>
<p>Now let’s do some posterior predictive checking: do posterior predictions look like the data? For this, we’ll make new predictions at the same values of <code>mpg</code> as were present in the original dataset (gray circles) and plot these with the observed data (colored circles):</p>
<div class="sourceCode" id="cb70"><html><body><pre class="r">mtcars_clean %&gt;%
  # we use `select` instead of `data_grid` here because we want to make posterior predictions
  # for exactly the same set of observations we have in the original data
  select(mpg) %&gt;%
  add_predicted_draws(m_cyl, seed = 1234) %&gt;%
  # recover original factor labels
  mutate(cyl = levels(mtcars_clean$cyl)[.prediction]) %&gt;%
  ggplot(aes(x = mpg, y = cyl)) +
  geom_count(color = "gray75") +
  geom_point(aes(fill = cyl), data = mtcars_clean, shape = 21, size = 2) +
  scale_fill_brewer(palette = "Dark2") +
  geom_label_repel(
    data = . %&gt;% ungroup() %&gt;% filter(cyl == "8") %&gt;% filter(mpg == max(mpg)) %&gt;% dplyr::slice(1),
    label = "posterior predictions", xlim = c(26, NA), ylim = c(NA, 2.8), point.padding = 0.3,
    label.size = NA, color = "gray50", segment.color = "gray75"
  ) +
  geom_label_repel(
    data = mtcars_clean %&gt;% filter(cyl == "6") %&gt;% filter(mpg == max(mpg)) %&gt;% dplyr::slice(1),
    label = "observed data", xlim = c(26, NA), ylim = c(2.2, NA), point.padding = 0.2,
    label.size = NA, segment.color = "gray35"
  )</pre></body></html></div>
<p><img src="tidy-rethinking_files/figure-html/unnamed-chunk-47-1.png" width="768"></p>
<p>This doesn’t look too bad — tails might be a bit long. Let’s check using another typical posterior predictive checking plot: many simulated distributions of the response (<code>cyl</code>) against the observed distribution of the response. For a continuous response variable this is usually done with a density plot; here, we’ll plot the number of posterior predictions in each bin as a line plot, since the response variable is discrete:</p>
<div class="sourceCode" id="cb71"><html><body><pre class="r">mtcars_clean %&gt;%
  select(mpg) %&gt;%
  add_predicted_draws(m_cyl, n = 100, seed = 12345) %&gt;%
  # recover original factor labels
  mutate(cyl = levels(mtcars_clean$cyl)[.prediction]) %&gt;%
  ggplot(aes(x = cyl)) +
  stat_count(aes(group = NA), geom = "line", data = mtcars_clean, color = "red", size = 3, alpha = .5) +
  stat_count(aes(group = .draw), geom = "line", position = "identity", alpha = .05) +
  geom_label(data = data.frame(cyl = "4"), y = 9.5, label = "posterior\npredictions",
    hjust = 1, color = "gray50", lineheight = 1, label.size = NA) +
  geom_label(data = data.frame(cyl = "8"), y = 14, label = "observed\ndata",
    hjust = 0, color = "red", lineheight = 1, label.size = NA)</pre></body></html></div>
<p><img src="tidy-rethinking_files/figure-html/unnamed-chunk-48-1.png" width="648"></p>
<p>This also looks good.</p>
<p>Another way to look at these posterior predictions might be as a scatterplot matrix. <code><a href="http://mjskay.github.io/tidybayes/reference/gather_pairs.html">tidybayes::gather_pairs()</a></code> makes it easy to generate long-format data frames suitable for creating custom scatterplot matrices (or really, arbitrary matrix-style small multiples plots) in ggplot using <code>facet_grid()</code>:</p>
<div class="sourceCode" id="cb72"><html><body><pre class="r">set.seed(12345)

mtcars_clean %&gt;%
  select(mpg) %&gt;%
  add_predicted_draws(m_cyl) %&gt;%
  # recover original factor labels. Must ungroup first so that the
  # factor is created in the same way in all groups; this is a workaround
  # because brms no longer returns labelled predictions (hopefully that
  # is fixed then this will no longer be necessary)
  ungroup() %&gt;%
  mutate(cyl = factor(levels(mtcars_clean$cyl)[.prediction])) %&gt;%
  # need .drop = FALSE to ensure 0 counts are not dropped
  group_by(.draw, .drop = FALSE) %&gt;%
  count(cyl) %&gt;%
  gather_pairs(cyl, n) %&gt;%
  ggplot(aes(.x, .y)) +
  geom_count(color = "gray75") +
  geom_point(data = mtcars_clean %&gt;% count(cyl) %&gt;% gather_pairs(cyl, n), color = "red") +
  facet_grid(vars(.row), vars(.col)) +
  xlab("Number of observations with cyl = col") +
  ylab("Number of observations with cyl = row") </pre></body></html></div>
<pre><code>## New names:
## * `6...41` -&gt; `6...1`
## * `6...42` -&gt; `6...2`
## * `6...43` -&gt; `6...3`
## * `6...44` -&gt; `6...4`
## * `6...45` -&gt; `6...5`
## * ...</code></pre>
<pre><code>## New names:
## * `6...4` -&gt; `6`
## * `8...4` -&gt; `8...2`
## * `8...6` -&gt; `8...3`</code></pre>
<p><img src="tidy-rethinking_files/figure-html/unnamed-chunk-49-1.png" width="648"></p>
</div>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">

        <nav id="toc" data-toggle="toc"><h2 data-toc-skip>Contents</h2>
    </nav>
</div>

</div>



      <footer><div class="copyright">
  <p>Developed by <a href="http://www.mjskay.com">Matthew Kay</a>.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="https://pkgdown.r-lib.org/">pkgdown</a> 1.5.0.</p>
</div>

      </footer>
</div>

  


  </body>
</html>
